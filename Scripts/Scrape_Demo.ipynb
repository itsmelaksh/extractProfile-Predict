{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your password:········\n"
     ]
    },
    {
     "ename": "NoSuchWindowException",
     "evalue": "Message: no such window: target window already closed\nfrom unknown error: web view not found\n  (Session info: chrome=68.0.3440.106)\n  (Driver info: chromedriver=2.41.578737 (49da6702b16031c40d63e5618de03a32ff6c197e),platform=Windows NT 10.0.17134 x86_64)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoSuchWindowException\u001b[0m                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-c1ddc76f43d0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    315\u001b[0m \u001b[1;31m# getting EBAC only links\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    316\u001b[0m \u001b[0msearch_url\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"https://www.linkedin.com/search/results/index/?keywords=master%20of%20technology%20business%20analytics%20National%20University%20of%20Singapore&origin=GLOBAL_SEARCH_HEADER\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 317\u001b[1;33m \u001b[0mlinks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_links\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msearch_url\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    318\u001b[0m \u001b[0mwrite_links_to_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlinks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    319\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-c1ddc76f43d0>\u001b[0m in \u001b[0;36mget_links\u001b[1;34m(search_url)\u001b[0m\n\u001b[0;32m    227\u001b[0m         \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"1: {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpage_source\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 229\u001b[1;33m     \u001b[0mscroll_smooth\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    230\u001b[0m \u001b[1;31m#    scroll_smooth(driver, \"up\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m     \u001b[0mhtml\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpage_source\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-c1ddc76f43d0>\u001b[0m in \u001b[0;36mscroll_smooth\u001b[1;34m(driver, direction)\u001b[0m\n\u001b[0;32m    197\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdirection\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m\"down\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m             \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute_script\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"window.scrollTo(0, document.body.scrollHeight* ({}/{}));\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute_script\u001b[1;34m(self, script, *args)\u001b[0m\n\u001b[0;32m    633\u001b[0m         return self.execute(command, {\n\u001b[0;32m    634\u001b[0m             \u001b[1;34m'script'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mscript\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 635\u001b[1;33m             'args': converted_args})['value']\n\u001b[0m\u001b[0;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    637\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mexecute_async_script\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscript\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    318\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    319\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 320\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    321\u001b[0m             response['value'] = self._unwrap_value(\n\u001b[0;32m    322\u001b[0m                 response.get('value', None))\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    240\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'alert'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 242\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    243\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_value_or_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNoSuchWindowException\u001b[0m: Message: no such window: target window already closed\nfrom unknown error: web view not found\n  (Session info: chrome=68.0.3440.106)\n  (Driver info: chromedriver=2.41.578737 (49da6702b16031c40d63e5618de03a32ff6c197e),platform=Windows NT 10.0.17134 x86_64)\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Sun Aug 12 18:49:07 2018\n",
    "\n",
    "@author: Steve Tan https://github.com/steve7an\n",
    "\"\"\"\n",
    "\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import getpass\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException, TimeoutException\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "import os\n",
    "import time\n",
    "import math\n",
    "\n",
    "import sys, os\n",
    "\n",
    "from shared_utility import *\n",
    "\n",
    "\n",
    "def login():\n",
    "    ''' Disable the 2fa so that we can automate the login, otherwise LinkedIn doesnt work '''\n",
    "    userid = 'cwtan_316@yahoo.com' #str(input(\"Enter email address: \"))\n",
    "    password = getpass.getpass('Enter your password:')\n",
    "    \n",
    "    \n",
    "    driver.get(\"https://www.linkedin.com\")\n",
    "    driver.implicitly_wait(imp_delay)\n",
    "    driver.find_element_by_xpath(\"\"\"//*[@id=\"login-email\"]\"\"\").send_keys(userid)\n",
    "    driver.find_element_by_xpath(\"\"\"//*[@id=\"login-password\"]\"\"\").send_keys(password)\n",
    "    driver.find_element_by_xpath(\"\"\"//*[@id=\"login-submit\"]\"\"\").click()\n",
    "\n",
    "\n",
    "def get_profile(connection_url):\n",
    "    ''' Given a profile link, get the needed details and return them as an dict'''\n",
    "    profile = {}\n",
    "    driver.get(connection_url)\n",
    "    driver.implicitly_wait(imp_delay)\n",
    "    \n",
    "    scroll_smooth(driver)\n",
    "    scroll_smooth(driver,\"up\")\n",
    "    b_exception = 0\n",
    "    try:\n",
    "        classname = 'experience-section'\n",
    "        myElem = WebDriverWait(driver, exp_delay).until(EC.presence_of_element_located((By.CLASS_NAME, classname)))\n",
    "        if debug_mode:\n",
    "            print (classname + \" loading is ready!\")\n",
    "    except Exception as e:\n",
    "        #print (\"{}: error {} loading took too much time!\".format(classname, e))\n",
    "        print('Error on line {} for section {} for url {}'.format(sys.exc_info()[-1].tb_lineno, classname, connection_url)\n",
    "        , type(e).__name__, e)\n",
    "        b_exception= 1\n",
    "\n",
    "        \n",
    "    try:\n",
    "        classname = 'education-section'\n",
    "        myElem = WebDriverWait(driver, exp_delay).until(EC.presence_of_element_located((By.CLASS_NAME, classname)))\n",
    "        if debug_mode:\n",
    "            print (classname + \" loading is ready!\")\n",
    "    except Exception as e:\n",
    "        #print (\"{}: error {} loading took too much time!\".format(classname, e))\n",
    "        print('Error on line {} for section {} for url {}'.format(sys.exc_info()[-1].tb_lineno, classname,connection_url)\n",
    "        , type(e).__name__, e)\n",
    "        b_exception= 1\n",
    "\n",
    "\n",
    "    html=driver.page_source   \n",
    "    soup=BeautifulSoup(html, \"lxml\") #specify parser or it will auto-select for you\n",
    "    #return soup\n",
    "   \n",
    "    name = soup.find(\"h1\", class_=\"pv-top-card-section__name\").get_text().strip()\n",
    "    title = soup.find(\"h2\", class_=\"pv-top-card-section__headline\").get_text().strip()\n",
    "    location = soup.find(\"h3\", class_=\"pv-top-card-section__location\").get_text().strip()\n",
    "    \n",
    "    positions = []\n",
    "    tmp = []\n",
    "    try:\n",
    "        i = 1\n",
    "        exps = soup.find(\"section\", class_=\"experience-section\").find_all(\"li\", class_=\"pv-position-entity\")\n",
    "        for exp in exps:\n",
    "            tmp = [s for s in exp.find(\"div\",class_=\"pv-entity__summary-info\").get_text().splitlines() if s.strip()]\n",
    "            \n",
    "            tmp_hash = {}\n",
    "            if len(tmp) == 1:\n",
    "                positions.append({\"Title\":tmp[0].strip()})\n",
    "            elif len(tmp) % 2 == 1: # having odd no of elements\n",
    "                tmp_hash[\"Title\"] = tmp[0].strip()\n",
    "\n",
    "                for j in range(1,len(tmp),2):\n",
    "                    # add handling for dates field\n",
    "                    if \"dates\" in tmp[j].lower():\n",
    "                        tmp_hash[tmp[j].title().replace(\" \",\"\") + \"Start\"] = tmp[j+1].split(\"–\")[0].strip()\n",
    "                        tmp_hash[tmp[j].title().replace(\" \",\"\") + \"End\"] = tmp[j+1].split(\"–\")[1].strip()\n",
    "                    else:\n",
    "                        tmp_hash[tmp[j].title().replace(\" \",\"\").replace(\".\",\"\")] = clean_text(tmp[j+1])\n",
    "                positions.append(tmp_hash)\n",
    "            else:\n",
    "                print (\"Unrecognised format for experience section found for url {}\".format(connection_url))\n",
    "            i = i + 1\n",
    "    except Exception as e:\n",
    "        #print (\"Experience section for {} encountered error {}\".format())\n",
    "        print('Error on line {} for url {}'.format(sys.exc_info()[-1].tb_lineno, connection_url)\n",
    "        , type(e).__name__, e)\n",
    "        b_exception = 1\n",
    "\n",
    "    educations = []\n",
    "    try:\n",
    "        i = 1\n",
    "        edus = soup.find(\"section\", class_=\"education-section\").find_all(\"div\", class_=\"pv-entity__summary-info\")\n",
    "        for edu in edus:\n",
    "            tmp = [s for s in edu.get_text().splitlines() if s.strip()]\n",
    "            if len(tmp) == 1:\n",
    "                educations.append({\"SchoolName\":tmp[0].strip()})\n",
    "            elif len(tmp) % 2 == 1: # having odd no of elements\n",
    "                tmp_hash = {}\n",
    "                tmp_hash[\"SchoolName\"] = tmp[0]\n",
    "                for j in range(1,len(tmp),2):\n",
    "                    # add handling for dates field\n",
    "                    if \"dates\" in tmp[j].lower():\n",
    "                        tmp_hash[tmp[j].title().replace(\" \",\"\") + \"Start\"] = tmp[j+1].split(\"–\")[0].strip()\n",
    "                        tmp_hash[tmp[j].title().replace(\" \",\"\") + \"End\"] = tmp[j+1].split(\"–\")[1].strip()\n",
    "                    else:\n",
    "                        tmp_hash[tmp[j].title().replace(\" \",\"\").replace(\".\",\"\")] = clean_text(tmp[j+1])\n",
    "                educations.append(tmp_hash)\n",
    "            else:\n",
    "                print (\"Unrecognised format for education section found for url {}\".format(connection_url))\n",
    "            i = i + 1\n",
    "    except Exception as e:\n",
    "#        print (\"Education section for url {} encountered error {}\".format(connection_url, e))\n",
    "        print('Error on line {} for url {}'.format(sys.exc_info()[-1].tb_lineno, connection_url)\n",
    "        , type(e).__name__, e)\n",
    "        b_exception = 1\n",
    "        \n",
    "    # recapture the profile later if an exception is found\n",
    "    if not (b_exception):\n",
    "        profile['name'] = name\n",
    "        profile['title'] = title\n",
    "        profile['location'] = location\n",
    "        profile['Url'] = connection_url\n",
    "        profile['positions'] = positions\n",
    "        profile['educations'] = educations\n",
    "\n",
    "    \n",
    "    return (profile)\n",
    "    \n",
    "    #mydivs = soup.findAll(\"div\", {\"class\": \"pv-top-card-v2-section__info\"})\n",
    "    #return (mydivs)\n",
    "\n",
    "\n",
    "def test_get_profiles():\n",
    "    connection_urls = ['https://www.linkedin.com/in/laxman-singh-pmp-6304a622/', 'https://www.linkedin.com/in/jelina-cheng-69b12a61/']\n",
    "    profiles = []\n",
    "    for url in connection_urls:\n",
    "        profiles.append(get_profile(url))\n",
    "        \n",
    "def setup_driver():\n",
    "    cwd = os.getcwd()\n",
    "    firefox_path = r'{}\\geckodriver.exe'.format(cwd)\n",
    "    #driver = webdriver.Firefox(executable_path=firefox_path)\n",
    "    #driver.set_page_load_timeout(30)\n",
    "\n",
    "    chrome_path=r'{}\\chromedriver.exe'.format(cwd)    \n",
    "    #option = webdriver.ChromeOptions()\n",
    "    #option.add_argument(\" — incognito\")\n",
    "    opts = Options()\n",
    "    opts.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.113 Safari/537.36\")\n",
    "    driver = webdriver.Chrome(chrome_path, chrome_options=opts)\n",
    "    return driver         \n",
    "\n",
    "\n",
    "        \n",
    "def scroll_around(driver):\n",
    "    '''Move around the page so that the links will load properly'''\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(get_sleep_delay())\n",
    "    if debug_mode:\n",
    "        print (\"3: {}\".format(len(driver.page_source)))\n",
    "\n",
    "    driver.execute_script(\"window.scrollTo(document.body.scrollHeight, document.body.scrollHeight/2);\")\n",
    "    time.sleep(get_sleep_delay())\n",
    "    if debug_mode:\n",
    "        print (\"5: {}\".format(len(driver.page_source)))\n",
    "    \n",
    "    driver.execute_script(\"window.scrollTo(document.body.scrollHeight/2, 0);\")\n",
    "    time.sleep(get_sleep_delay())\n",
    "    if debug_mode:\n",
    "        print (\"6: {}\".format(len(driver.page_source)))\n",
    "    \n",
    "def scroll_smooth(driver, direction=\"down\"):\n",
    "    steps = 900\n",
    "    if direction==\"down\":\n",
    "        for i in range(1, steps+1):\n",
    "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight* ({}/{}));\".format(i, steps))\n",
    "    else:\n",
    "        for i in range(1, steps+1):\n",
    "            driver.execute_script(\"window.scrollTo(document.body.scrollHeight, document.body.scrollHeight* ({}/{}));\".format(steps-i, steps))\n",
    "    time.sleep(get_sleep_delay())\n",
    "    if debug_mode:\n",
    "        print (\"7: {}\".format(len(driver.page_source)))\n",
    "\n",
    "\n",
    "def get_profile_links(soup):\n",
    "    links = []\n",
    "    profiles = soup.find_all(\"div\",class_='search-result__info')\n",
    "    for p in profiles:\n",
    "        href_txt = p.find(\"a\",href=True)['href']\n",
    "        if len(href_txt) > 1:\n",
    "            url = \"https://www.linkedin.com{}\".format(href_txt)\n",
    "            links.append(url)\n",
    "        else:\n",
    "            print (\"Unmatch url {}\".format(href_txt))\n",
    "    return links\n",
    "\n",
    "def get_links(search_url):\n",
    "    profile_links = []\n",
    "    driver.implicitly_wait(imp_delay)\n",
    "    driver.get(search_url)\n",
    "#    time.sleep(get_sleep_delay())\n",
    "    \n",
    "    if debug_mode:\n",
    "        print (\"1: {}\".format(len(driver.page_source)))\n",
    "\n",
    "    scroll_smooth(driver)\n",
    "#    scroll_smooth(driver, \"up\")\n",
    "    html=driver.page_source\n",
    "    soup=BeautifulSoup(html, \"lxml\") #specify parser or it will auto-select for you\n",
    "    #return soup\n",
    "\n",
    "    '''Given a search linkedin Url, retrieve all the profiles link'''\n",
    "    #get each profile link in the page and add them to the array\n",
    "    #search-result__info\n",
    "    tmp = get_profile_links(soup)\n",
    "    profile_links.extend(tmp)\n",
    "    print (\"Fetching {} profiles\".format(len(tmp)))\n",
    "\n",
    "    #get the paging links and loop through each one\n",
    "    padding = 1 # for the last page \n",
    "    total_pages = math.ceil(int(soup.find('h3',class_='search-results__total').get_text().replace(\",\",\"\").split()[1])/10) + padding\n",
    "    \n",
    "    #bounded to linkedin 100 pages\n",
    "    if total_pages > 100:\n",
    "        total_pages = 101\n",
    "        \n",
    "    for i in range(2,total_pages):\n",
    "        driver.implicitly_wait(imp_delay) # seconds\n",
    "        driver.get(search_url + \"page&page={}\".format(i))\n",
    "#        time.sleep(get_sleep_delay())\n",
    "        \n",
    "        scroll_smooth(driver)\n",
    "#        scroll_smooth(driver, \"up\")\n",
    "\n",
    "        html=driver.page_source\n",
    "        soup=BeautifulSoup(html, \"lxml\") #specify parser or it will auto-select for you\n",
    "        tmp = get_profile_links(soup)\n",
    "        profile_links.extend(tmp)\n",
    "        print (\"Fetching {} profiles\".format(len(tmp)))\n",
    "    \n",
    "        print(\"Processing page {} out of total page {}\".format(i, total_pages))\n",
    "    #return the array\n",
    "    return profile_links\n",
    "\n",
    "def create_profiles_collection(db, profiles):\n",
    "    # Ensure everything is deleted from example collection.\n",
    "    # ... The name can anything to specify a collection.\n",
    "    #db.hireu.delete_many({})\n",
    "    \n",
    "    #insert into hireu table\n",
    "    db.hireu.insert_many(profiles)\n",
    "    \n",
    "    # Find all things.\n",
    "#    cursor = db.hireu.find({})\n",
    "#    print(\"FIND ALL\")\n",
    "#    for c in cursor:\n",
    "#        print(c)\n",
    "\n",
    "def get_new_links_only(db, links):\n",
    "    ''' check against mongodb to return only the new links '''\n",
    "    result = db.hireu.find({ \"Url\" : { \"$in\": links}})\n",
    "    try:\n",
    "        url = \"\"\n",
    "        for doc in result:\n",
    "            url = doc['Url']\n",
    "            links.remove(url)\n",
    "    except Exception as e:\n",
    "        print('Error on line {} for url {}'.format(sys.exc_info()[-1].tb_lineno, url)\n",
    "        , type(e).__name__, e)\n",
    "    \n",
    "    return links\n",
    "\n",
    "random.seed(1098)\n",
    "debug_mode = 0\n",
    "#sleep_delay = 1\n",
    "exp_delay = 60 #60 secs is sufficient?\n",
    "imp_delay = 3\n",
    "driver = setup_driver()\n",
    "login()\n",
    "\n",
    "#search_url = 'https://www.linkedin.com/search/results/index/?keywords=nus%20iss%20master%20tech&origin=GLOBAL_SEARCH_HEADER'\n",
    "\n",
    "# NUS ISS grads only?\n",
    "#search_url = \"https://www.linkedin.com/search/results/index/?keywords=%22National%20University%20of%20Singapore%22%20or%20%22NUS%22%20or%20%22Institute%20of%20System%20Science%22%20or%20Master&origin=GLOBAL_SEARCH_HEADER\"\n",
    "\n",
    "# current set of links - not very accurate for KE students\n",
    "#search_url = \"https://www.linkedin.com/search/results/index/?keywords=Institute%20System%20Science%20NUS&origin=GLOBAL_SEARCH_HEADER\"\n",
    "\n",
    "# trying KE only links\n",
    "#search_url = \"https://www.linkedin.com/search/results/index/?keywords=master%20of%20technology%20knowledge%20engineering%20National%20University%20of%20Singapore&origin=GLOBAL_SEARCH_HEADER\"\n",
    "\n",
    "# getting EBAC only links\n",
    "search_url = \"https://www.linkedin.com/search/results/index/?keywords=master%20of%20technology%20business%20analytics%20National%20University%20of%20Singapore&origin=GLOBAL_SEARCH_HEADER\"\n",
    "links = get_links(search_url)\n",
    "write_links_to_file(links)\n",
    "\n",
    "#links = ['https://www.linkedin.com/in/vandana-vamadevan-pillai-121b8774/','https://www.linkedin.com/in/wei-gang-40b3647/',\n",
    "#         'https://www.linkedin.com/in/nickguan/','https://www.linkedin.com/in/toon-seng-foo-2726701a/']\n",
    "\n",
    "#links = ['https://www.linkedin.com/in/meiyou-ye-9643075/'\n",
    "#,'https://www.linkedin.com/in/siong-guan-ang-a6a759a6/'\n",
    "#,'https://www.linkedin.com/in/zheming-chen-3b667064/'\n",
    "#,'https://www.linkedin.com/in/jianlin-luo-33236735/'\n",
    "#,'https://www.linkedin.com/in/lamboonsoon/'\n",
    "#,'https://www.linkedin.com/in/wilsonwan/']\n",
    "#reload from links file to continue\n",
    "#db = setupMongoDB()\n",
    "#cwd = os.getcwd()\n",
    "#links_file = '{}\\data\\links20180823124257.txt'.format(cwd)\n",
    "#links = read_links_from_file(links_file)\n",
    "\n",
    "unique_links = get_new_links_only(db, links)\n",
    "print (len(unique_links))\n",
    "#\n",
    "total_links = len(unique_links)\n",
    "profiles = []\n",
    "for i, url in enumerate(unique_links):\n",
    "    print (\"processing {} out of {} links.\".format(i + 1, total_links))\n",
    "    profiles.append(get_profile(url))\n",
    "    \n",
    "#driver.quit()\n",
    "#\n",
    "##\n",
    "#cwd = os.getcwd()\n",
    "#file_path  = '{}\\data\\data_formatted{}.json'.format(cwd,get_timestamp())\n",
    "#export_profiles_as_json(file_path, profiles)\n",
    "##profiles = load_profiles_from_json(file_path)\n",
    "#\n",
    "create_profiles_collection(db, profiles)\n",
    "\n",
    "#query_db()\n",
    "#\n",
    "#write_links_to_file(links)\n",
    "\n",
    "\n",
    "#one = [1,2,3]\n",
    "#two = [4,5,6]\n",
    "#one.extend(two)\n",
    "#print (one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
